{
  "llm_models": {
    "llama3.2:3b": {
      "name": "Llama 3.2 3B",
      "size": "2GB",
      "speed": "fast",
      "quality": "good",
      "min_ram_gb": 4,
      "min_vram_gb": 0,
      "description": "Fast, good quality - recommended for most users",
      "provider": "Meta",
      "use_cases": ["general", "summarization", "clustering"],
      "languages": ["en", "es", "fr", "de", "it", "pt", "ru", "zh", "ja"],
      "context_length": 131072,
      "recommended": true,
      "efficiency_metrics": {
        "power_consumption_relative": "medium",
        "memory_efficiency": "good"
      }
    },
    "llama3.2:1b": {
      "name": "Llama 3.2 1B",
      "size": "1.3GB",
      "speed": "fastest",
      "quality": "basic",
      "min_ram_gb": 2,
      "min_vram_gb": 0,
      "description": "Fastest, basic quality - for low-resource systems",
      "provider": "Meta",
      "use_cases": ["low-resource", "basic-summarization"],
      "languages": ["en", "es", "fr", "de", "it"],
      "context_length": 131072,
      "recommended": false
    },
    "qwen3:0.6b": {
      "name": "Qwen3 0.6B",
      "size": "0.7GB",
      "speed": "fastest",
      "quality": "basic",
      "min_ram_gb": 2,
      "min_vram_gb": 0,
      "description": "Ultra-lightweight model with thinking mode support",
      "provider": "Alibaba",
      "use_cases": ["low-resource", "edge-computing", "mobile"],
      "languages": ["en", "zh", "ja", "ko", "es", "fr", "de", "ru", "ar", "100+ languages"],
      "context_length": 32768,
      "recommended": false
    },
    "qwen3:1.7b": {
      "name": "Qwen3 1.7B",
      "size": "1.1GB",
      "speed": "fastest",
      "quality": "good",
      "min_ram_gb": 2,
      "min_vram_gb": 0,
      "description": "Efficient model with dual thinking/non-thinking modes",
      "provider": "Alibaba",
      "use_cases": ["reasoning", "code", "multilingual", "low-resource"],
      "languages": ["en", "zh", "ja", "ko", "es", "fr", "de", "ru", "ar", "100+ languages"],
      "context_length": 32768,
      "recommended": true
    },
    "qwen3:4b": {
      "name": "Qwen3 4B",
      "size": "2.5GB",
      "speed": "fast",
      "quality": "high",
      "min_ram_gb": 4,
      "min_vram_gb": 0,
      "description": "Strong reasoning and coding, outperforms larger legacy models",
      "provider": "Alibaba",
      "use_cases": ["reasoning", "code", "agents", "tool-use"],
      "languages": ["en", "zh", "ja", "ko", "es", "fr", "de", "ru", "ar", "100+ languages"],
      "context_length": 32768,
      "recommended": false
    },
    "qwen3:8b": {
      "name": "Qwen3 8B",
      "size": "4.7GB",
      "speed": "medium",
      "quality": "high",
      "min_ram_gb": 6,
      "min_vram_gb": 0,
      "description": "Balanced performance with excellent multilingual and reasoning",
      "provider": "Alibaba",
      "use_cases": ["balanced", "multilingual", "reasoning", "code", "agents"],
      "languages": ["en", "zh", "ja", "ko", "es", "fr", "de", "ru", "ar", "100+ languages"],
      "context_length": 131072,
      "recommended": false
    },
    "phi4:3.8b": {
      "name": "Phi-4 Mini 3.8B",
      "size": "2.3GB",
      "speed": "fast",
      "quality": "high",
      "min_ram_gb": 4,
      "min_vram_gb": 0,
      "description": "Microsoft's latest SLM with enhanced reasoning, 128K context",
      "provider": "Microsoft",
      "use_cases": ["reasoning", "math", "code", "analysis"],
      "languages": ["en", "es", "fr", "de", "zh", "ja", "ko", "ar", "ru", "20+ languages"],
      "context_length": 128000,
      "recommended": true
    },
    "mistral:7b": {
      "name": "Mistral 7B",
      "size": "4.1GB",
      "speed": "medium",
      "quality": "high",
      "min_ram_gb": 6,
      "min_vram_gb": 0,
      "description": "Good balance of speed and quality",
      "provider": "Mistral AI",
      "use_cases": ["balanced", "multilingual", "reasoning"],
      "languages": ["en", "fr", "de", "es", "it"],
      "context_length": 32768,
      "recommended": false
    },
    "gemma3n:e2b": {
      "name": "Gemma 3n E2B",
      "size": "1.2GB",
      "speed": "fastest",
      "quality": "good",
      "min_ram_gb": 2,
      "min_vram_gb": 0,
      "description": "Google's edge-optimized multimodal model (text, image, audio)",
      "provider": "Google",
      "use_cases": ["multimodal", "edge-computing", "mobile", "speech", "vision"],
      "languages": ["en", "es", "fr", "de", "it", "pt", "zh", "ja", "140+ languages"],
      "context_length": 32768,
      "recommended": false
    },
    "gemma3n:e4b": {
      "name": "Gemma 3n E4B",
      "size": "2.2GB",
      "speed": "fast",
      "quality": "high",
      "min_ram_gb": 3,
      "min_vram_gb": 0,
      "description": "Multimodal model with MatFormer architecture (text, image, audio, video)",
      "provider": "Google",
      "use_cases": ["multimodal", "efficient", "edge-computing", "vision", "audio"],
      "languages": ["en", "es", "fr", "de", "it", "pt", "zh", "ja", "140+ languages"],
      "context_length": 32768,
      "recommended": true
    },
    "codellama:7b": {
      "name": "CodeLlama 7B",
      "size": "3.8GB",
      "speed": "medium",
      "quality": "high",
      "min_ram_gb": 6,
      "min_vram_gb": 0,
      "description": "Meta model, optimized for code understanding",
      "provider": "Meta",
      "use_cases": ["code", "programming", "technical-content", "documentation"],
      "languages": ["en"],
      "context_length": 16384,
      "recommended": false
    }
  },
  "embedding_models": {
    "nomic-embed-text": {
      "name": "Nomic Embed Text",
      "size": "274MB",
      "dimensions": 768,
      "quality": "high",
      "min_ram_gb": 1,
      "description": "Best general purpose embedding model",
      "provider": "Nomic AI",
      "use_cases": ["general", "semantic-search", "clustering"],
      "max_sequence_length": 8192,
      "recommended": true
    },
    "all-minilm": {
      "name": "All-MiniLM",
      "size": "90MB",
      "dimensions": 384,
      "quality": "good",
      "min_ram_gb": 0.5,
      "description": "SentenceTransformers compatible, lightweight",
      "provider": "Microsoft",
      "use_cases": ["lightweight", "fast", "compatible"],
      "max_sequence_length": 512,
      "recommended": false
    },
    "mxbai-embed-large": {
      "name": "MxBai Embed Large",
      "size": "669MB",
      "dimensions": 1024,
      "quality": "highest",
      "min_ram_gb": 2,
      "description": "Highest quality embeddings, larger size",
      "provider": "MixedBread AI",
      "use_cases": ["high-quality", "research", "precision"],
      "max_sequence_length": 512,
      "recommended": false
    }
  },
  "hardware_profiles": {
    "low_resource": {
      "max_ram_gb": 4,
      "recommended_llm": "qwen3:1.7b",
      "recommended_embedding": "all-minilm",
      "description": "For systems with limited resources"
    },
    "medium_resource": {
      "max_ram_gb": 8,
      "recommended_llm": "gemma3n:e4b",
      "recommended_embedding": "nomic-embed-text",
      "description": "For typical desktop/laptop systems"
    },
    "high_resource": {
      "max_ram_gb": 16,
      "recommended_llm": "qwen3:8b",
      "recommended_embedding": "mxbai-embed-large",
      "description": "For powerful workstations"
    },
    "gpu_optimized": {
      "min_vram_gb": 4,
      "recommended_llm": "phi4:3.8b",
      "recommended_embedding": "mxbai-embed-large",
      "description": "For systems with dedicated GPU"
    }
  },
  "model_categories": {
    "speed_optimized": ["qwen3:0.6b", "qwen3:1.7b", "gemma3n:e2b", "llama3.2:1b"],
    "quality_optimized": ["qwen3:8b", "phi4:3.8b", "mistral:7b"],
    "balanced": ["llama3.2:3b", "qwen3:4b", "gemma3n:e4b"],
    "multilingual": ["qwen3:1.7b", "qwen3:4b", "qwen3:8b", "gemma3n:e4b", "mistral:7b"],
    "code_focused": ["qwen3:4b", "phi4:3.8b", "codellama:7b"],
    "resource_efficient": ["qwen3:0.6b", "qwen3:1.7b", "gemma3n:e2b", "llama3.2:1b", "all-minilm"],
    "multimodal": ["gemma3n:e2b", "gemma3n:e4b"],
    "reasoning_focused": ["qwen3:1.7b", "qwen3:4b", "phi4:3.8b"],
    "agent_capable": ["qwen3:4b", "qwen3:8b"]
  }
}
